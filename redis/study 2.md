- [一、键值设计](#一键值设计)
  - [1. key名设计](#1-key名设计)
  - [2. value设计](#2-value设计)
- [二、命令使用](#二命令使用)
- [三、客户端使用](#三客户端使用)
- [四、相关工具](#四相关工具)
- [五 附录：删除bigkey](#五-附录删除bigkey)
- [击穿](#击穿)
- [穿透](#穿透)
- [雪崩](#雪崩)
- [REDIS跟MYSQL数据同步](#redis跟mysql数据同步)
- [Redis数据类型](#redis数据类型)
  - [字符串](#字符串)
  - [散列/哈希可以存储多达2^32 - 1个健-值对(超过40亿个)](#散列哈希可以存储多达232---1个健-值对超过40亿个)
  - [列表](#列表)
  - [集合](#集合)
  - [可排序集合](#可排序集合)
- [Redis 6.0 新特性](#redis-60-新特性)
  - [多线程](#多线程)
  - [ACL权限控制](#acl权限控制)
  - [Tracking](#tracking)
- [Redis Cluster规模的限制因素](#redis-cluster规模的限制因素)
- [Redis事务机制](#redis事务机制)
- [Redis性能问题排查](#redis性能问题排查)
- [实例上限maxmory](#实例上限maxmory)
- [fork耗时长](#fork耗时长)
- [内存大页](#内存大页)
- [AOF](#aof)
- [Redis运用场景总结](#redis运用场景总结)
- [内存碎片](#内存碎片)
- [数据倾斜](#数据倾斜)
- [缓存污染](#缓存污染)
- [bigkeys 分析](#bigkeys-分析)
- [缓存淘汰策略](#缓存淘汰策略)
  - [备份恢复之AOF](#备份恢复之aof)
  - [备份恢复之RDB](#备份恢复之rdb)
- [Redis数据同步方案](#redis数据同步方案)
- [proxy支持](#proxy支持)
- [Redis 跨机房双向同步](#redis-跨机房双向同步)

# 一、键值设计
## 1. key名设计

(1)【建议】: 可读性和可管理性

以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id
```
ugc:video:1
```
(2)【建议】：简洁性

保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：
```
user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}
```
(3)【强制】：不要包含特殊字符

反例：包含空格、换行、单双引号以及其他转义字符

## 2. value设计

(1)【强制】：拒绝bigkey(防止网卡流量、慢查询)

string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。

反例：一个包含200万个元素的list。

非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法

(2)【推荐】：选择适合的数据类型

例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)
```
反例：
set user:1:name tom
set user:1:age 19
set user:1:favor football

正例:
hmset user:1 name tom age 19 favor football
```
3.【推荐】：控制key的生命周期，redis不是垃圾桶

建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。

# 二、命令使用
1.【推荐】 O(N)命令关注N的数量

例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。

2.【推荐】：禁用命令

禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。

3.【推荐】合理使用select

redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。

4.【推荐】使用批量操作提高效率

原生命令：例如mget、mset。

非原生命令：可以使用pipeline提高效率。

但要注意控制一次批量操作的元素个数 (例如500以内，实际也和元素字节数有关)。

注意两者不同：
```
1. 原生是原子操作，pipeline是非原子操作。
2. pipeline可以打包不同的命令，原生做不到
3. pipeline需要客户端和服务端同时支持。
5.【建议】Redis事务功能较弱，不建议过多使用
Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)
6.【建议】Redis集群版本在使用Lua上有特殊要求：
    •	1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，"-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array"
    •	2.所有key，必须在1个slot上，否则直接返回error, "-ERR eval/evalsha command keys must in same slot"
7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。
```
# 三、客户端使用
1.【推荐】

避免多个应用使用一个Redis实例

正例：不相干的业务拆分，公共数据做服务化。

2.【推荐】

使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：
```
执行命令如下：
Jedis jedis = null;
try {
    jedis = jedisPool.getResource();
    //具体的命令
    jedis.executeCommand()
} catch (Exception e) {
    logger.error("op key {} error: " + e.getMessage(), key, e);
} finally {
    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
    if (jedis != null)
        jedis.close();
}
```
下面是JedisPool优化方法的文章:

•	Jedis常见异常汇总
•	JedisPool资源池优化

3.【建议】

高并发下建议客户端添加熔断功能(例如netflix hystrix)

4.【推荐】

设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）

5.【建议】

根据业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。

默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。

其他策略如下：
```
•	allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
•	allkeys-random：随机删除所有键，直到腾出足够空间为止。
•	volatile-random:随机删除过期键，直到腾出足够空间为止。
•	volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。
•	noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。
```
# 四、相关工具
1.【推荐】：数据同步

redis间数据同步可以使用：redis-port

2.【推荐】：big key搜索

redis大key搜索工具

3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)

facebook的redis-faina

阿里云Redis已经在内核层面解决热点key问题，欢迎使用。

# 五 附录：删除bigkey
1. 下面操作可以使用pipeline加速。
2. redis 4.0已经支持key的异步删除，欢迎使用。
3. Hash删除: hscan + hdel
4. List删除: ltrim
5. Set删除: sscan + srem
6. SortedSet删除: zscan + zrem

# 击穿
redis缓存击穿是指某一个非常热点的key(即在客户端搜索的比较多的关键字)突然失效了,这时从客户端发送的大量的请求在redis里找不到这个key，就会去数据里找，最终导致数据库压力过大崩掉。 解决：
```
•	1.将value的时效设置成永不过期 这种方式非常简单粗暴但是安全可靠。但是非常占用空间对内存消耗也是极大。个人并不建议使用该方法，应该根据具体业务逻辑来操作。
•	2.使用Timetask做一个定时任务 使用Timetask做定时，每隔一段时间对一些热点key进行数据库查询，将查询出的结果更新至redis中。前条件是不会给数据库过大的压力。
•	3.通过synchronized+双重检查机制 当发生reids穿透的时候，这时海量请求发送到数据库。这时我们的解决办法是只让只让一个线程去查询这个热点key，其它线程保持阻塞状态(可以让它们sleep几秒)。 当这个进入数据库的线程查询出key对应的value时，我们再将其同步至redis的缓存当中，其它线程睡醒以后再重新去redis里边请求数据
```
# 穿透
因为不良用户恶意频繁查询才会对系统造成很大的问题: key缓存并且数据库不存在，所以每次查询都会查询数据库从而导致数据库崩溃。 解决：
```
•	1.当类似的请求发过来，无论查出什么结果都放入redis缓存
•	2.拉黑其ip
•	3.对请求的参数进行合法性校验，在判断其不合法的前提下直接return掉
•	4.使用布隆过滤器。布隆过滤器可能会造成误判，从而穿透redis进入DB，但是这个误判概率是非常小的。
```
# 雪崩
和击穿类似，不同的是击穿是一个热点key某时刻失效，而雪崩是大量的热点key在一瞬间失效 解决：
```
•	1.设置缓存时,随机初始化其失效时间。如果是redis的key同时失效,可采取该办法,具体失效时间根据业务情况决定…
•	2.将不同的热点key放置到不同的节点上去。因redis一般都是集群部署,将不同的热点key平均的放置到不同节点,也可以有效避免雪崩。
•	3.将value的时效设置成永不过期
•	4.使用Timetask做一个定时任务，在失效之前重新刷redis缓存
```

# REDIS跟MYSQL数据同步
1. 先清除缓存，再更新数据库的方式显然是不行的，可能存在数据永远不正确的情况。 
2. 先更新数据库再清缓存的方式，虽然可能会存在少数的错误数据的情况，但是相对来说，后续的查询可以得到更新的值。

# Redis数据类型
## 字符串
```
127.0.0.1:6401> set name ""yiibai.com"" 
(error) MOVED 5798 127.0.0.1:7401
127.0.0.1:6401> get name
(error) MOVED 5798 127.0.0.1:7401
```
## 散列/哈希可以存储多达2^32 - 1个健-值对(超过40亿个)
```
127.0.0.1:6401> HMSET ukey username ""yiibai"" password ""passswd123"" points 200
OK
127.0.0.1:6401> hmget ukey password
1) ""passswd123""
127.0.0.1:6401> HGETALL ukey
1) ""username""
2) ""yiibai""
3) ""password""
4) ""passswd123""
5) ""points""
6) ""200""
```
## 列表
最大长度为2^32 - 1个元素(4294967295，每个列表可容纳超过40亿个元素) Redis列表只是字符串列表，按插入顺序排序。您可以向Redis列表的头部或尾部添加元素
```
127.0.0.1:6401> lpush alist redis 
(integer) 1
127.0.0.1:6401> lpush alist mongodb 
(integer) 2
127.0.0.1:6401> lrange alist 0 1
1) ""mongodb""
2) ""redis""
127.0.0.1:6401> lrange alist 0 0
1) ""mongodb""
127.0.0.1:6401>
```
## 集合
一个集合中的最大成员数量为2^32 - 1(即4294967295，每个集合中元素数量可达40亿个)
```
redis 127.0.0.1:6379> sadd yiibailist redis 
(integer) 1 
redis 127.0.0.1:6379> sadd yiibailist mongodb 
(integer) 1 
redis 127.0.0.1:6379> sadd yiibailist sqlite 
(integer) 1 
redis 127.0.0.1:6379> sadd yiibailist sqlite 
(integer) 0 
redis 127.0.0.1:6379> smembers yiibailist  
1) ""sqlite"" 
2) ""mongodb"" 
3) ""redis""
```
## 可排序集合
```
redis 127.0.0.1:6379> zadd yiibaiset 0 redis
(integer) 1 
redis 127.0.0.1:6379> zadd yiibaiset 0 mongodb
(integer) 1 
redis 127.0.0.1:6379> zadd yiibaiset 1 sqlite
(integer) 1 
redis 127.0.0.1:6379> zadd yiibaiset 1 sqlite
(integer) 0 
redis 127.0.0.1:6379> ZRANGEBYSCORE yiibaiset 0 1000  
1) ""mongodb"" 
2) ""redis"" 
```

# Redis 6.0 新特性
## 多线程
在Redis 6.0中，最受关注的还是其新增的多线性特性、一直以来，大家所熟知的都是Redis的单线程。
虽然数据删除、RDB的生成、AOF重写等功能可以使用后台线程或者子进程来处理，但网络IO的处理到这个命令的处理，一直都是单线程进行的。随着网络硬件性能的提升，单线程处理网络请求的速度低于网络硬件的速度时，会导致了Redis的性能瓶颈会出现在网络IO上。
为了解决这个性能瓶颈，一种是让网络请求不在内核里执行，即使用用户态网络协议栈代替内核网络协议栈，一种是采用多IO线程处理网络需求，从并发度的角度来提高网络请求处理的能力。虽然避开内核可以很好地提升请求的处理效率，但使用用户态网络协议栈，需要修改Redis源码中网络相关的部分，这会带来额外的开发工作同时新的变动也可能会带来新的bug，影响redis的稳定性。
所以在6.0的版本中，Redis官方采用了第二种方法，使用多IO来处理网络请求，在命令的读写操作上，仍是使用单线程来处理。
这样做主要是因为，出现瓶颈的一般都是在网络请求处理上，使用多IO并行处理就提升了整体的处理性能。在命令的处理上继续使用单线程，也避免了事务原子性、锁互斥、资源争用等来带的性能损耗。在实现上，大致分为以下四步：
```
     （1）服务端与客户端建议socket连接并分配处理线程
     （2）IO线程读取并解析客户端请求
     （3）主线程执行请求的命令操作，将返回的结果写入缓冲区
     （4）IO线程回写socket和主线程清空全局队列
```
## ACL权限控制
 在Redis 6.0之前，Redis实例只有一个默认用户，可以设置为无密码访问，也可以针对这个用户设置密码。
这个默认用户可以拥有最大权限，可以执行所有的命令。规避高危命令只能通过重命名的方式来避免客户端的直接调用。
为了更细力度的控制访问权限，Redis 6.0版本开始支持了多用户的创建以及权限的控制；我们可以使用acl setuser来创建用户，使用（+）（-）来控制用户的权限。同时还可以以key为力度来设置访问权限，具体是通过~key的全前缀来实现。  

## Tracking
 相比于之前版本，Redis实现了Tracking功能，也就是客户端缓存功能。

Redis客户端可以把读取的数据缓存在业务应用本地，那么应用就可以在本地快速读取数据了。

本地缓存同时会带来这样一个问题：当数据被修改或者过期了，如何通知客户端处理这部分变化的数据。在Redis 6.0 中的Tracking功能中，通过两种模式来解决这个问题。

一种是普通模式，可以通过client tracking on|off来控制开关。在这个模式下，Redis实例会在服务端记录客户端读取过的key并监控这个key是否有修改；一旦key发生了变化，就会通知客户端缓存失效了，此后不会再次发送这个key的变化，除非客户端再次读取了这个key。

另一种模式是广播模式，在这个模式下，服务端会给客户端广播所有key的失效情况，缺点是当有key被频繁改动时，服务端需要发送大量的广播，就会消耗大量的网络带宽。

在实际情况中，最优的方案是吧希望tracking的key的前缀进行注册，当带有注册前缀的key被修改时，服务端会把失效消息广播给所有注册的客户端。此功能需要客户端使用前面提到的RESP3 协议，在RESP 2 协议中，需要使用重定向模式才能实现。

# Redis Cluster规模的限制因素
Redis Cluster 能保存的数据量以及支撑的吞吐量，跟集群的实例规模密切相关。Redis 官方给出了 Redis Cluster 的规模上限，就是一个集群运行 1000 个实例。

为了避免过多的心跳消息挤占集群带宽，我们可以调大 cluster-node-timeout值，比如说调大到 20 秒或 25 秒。这样一来， PONG 消息接收超时的情况就会有所缓解，单实例也不用频繁地每秒执行 10 次心跳发送操作了。

当然，我们也不要把 cluster-node-timeout 调得太大，否则，如果实例真的发生了故障，我们就需要等待 cluster-node-timeout 时长后，才能检测出这个故障，这又会导致实际的故障恢复时间被延长，会影响到集群服务的正常使用。为了验证调整 cluster-node-timeout 值后，是否能减少心跳消息占用的集群网络带宽，可以在调整 cluster-node-timeout 值的前后，使用 tcpdump 命令抓取实例发送心跳信息网络包的情况。

# Redis事务机制
Redis 实现事务

事务的执行过程包含三个步骤，Redis 提供了 MULTI、EXEC 两个命令来完成这三个步骤。

第一步，客户端要使用一个命令显式地表示一个事务的开启。在 Redis 中，这个命令就是MULTI。

第二步，客户端把事务中本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 Redis 本身提供的数据读写命令，例如 GET、SET 等。不过，这些命令虽然被客户端发送到了服务器端，但 Redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行。

第三步，客户端向服务器端发送提交事务的命令，让数据库实际执行第二步中发送的具体操作。Redis 提供的 EXEC 命令就是执行事务提交的。当服务器端收到 EXEC 命令后，才会实际执行命令队列中的所有命令。

Redis 的事务机制能保证哪些属性

如果事务正常执行，没有发生任何错误，那么，MULTI 和 EXEC 配合使用，就可以保证多个操作都完成。但是，如果事务执行发生错误了，原子性还能保证吗？我们需要分三种情况来看。

第一种情况是，在执行 EXEC 命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被 Redis 实例判断出来了。对于这种情况，在命令入队时，Redis 就会报错并且记录下这个错误。此时，我们还能继续提交命令操作。等到执行了 EXEC 命令之后，Redis 就会拒绝执行所有提交的命令操作，返回事务失败的结果。这样一来，事务中的所有命令都不会再被执行了，保证了原子性。

命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。日志并没有开启，那么实例重启后，数据也都没法恢复了，此时，也就谈不上原子性了。

# Redis性能问题排查
单个实例的 OPS 能够达到 10W 左右。但也正因此如此，当我们在使用 Redis 时，如果发现操作延迟变大的情况，就会与我们的预期不符。

如果发现业务服务 API 响应延迟变长，首先需要先排查服务内部，究竟是哪个环节拖慢了整个服务。

比较高效的做法是，在服务内部集成链路追踪，也就是在服务访问外部依赖的出入口，记录下每次请求外部依赖的响应延时。如果发现确实是操作 Redis 的这条链路耗时变长了，那么此刻需要把焦点关注在业务服务到 Redis 这条链路上。

从业务服务到 Redis 这条链路变慢的原因可能也有 2 个：业务服务器到 Redis 服务器之间的网络存在问题，例如网络线路质量不佳，网络数据包在传输时存在延迟、丢包等情况；Redis 本身存在问题，需要进一步排查是什么原因导致 Redis 变慢。通常来说，第一种情况发生的概率比较小，如果是服务器之间网络存在问题，那部署在这台业务服务器上的所有服务都会发生网络延迟的情况，此时你需要联系网络运维同事，让其协助解决网络问题。

从 Redis 角度来排查，是否存在导致变慢的场景，以及都有哪些因素会导致 Redis 的延迟增加，然后针对性地进行优化。

为了避免业务服务器到 Redis 服务器之间的网络延迟，需要直接在 Redis 服务器上测试实例的响应延迟情况。执行以下命令，就可以测试出这个实例 60 秒内的最大响应延迟：
```
$ redis-cli -h 127.0.0.1 -p 6379 --intrinsic-latency 60
```
还可以使用以下命令，查看一段时间内 Redis 的最小、最大、平均访问延迟：
```
$ redis-cli -h 127.0.0.1 -p 6379 --latency-history -i 1
```
导致 Redis 变慢的因素。

①使用复杂度过高的命令

首先，第一步，通过查看慢日志，我们就可以知道在什么时间点，执行了哪些命令比较耗时。
如果应用程序执行的 Redis 命令有以下特点，那么有可能会导致操作延迟变大：
经常使用 O(N) 以上复杂度的命令，例如 SORT、SUNION、ZUNIONSTORE 聚合类命令；使用 O(N) 复杂度的命令，但 N 的值非常大
第一种情况导致变慢的原因在于，Redis 在操作内存数据时，时间复杂度过高，要花费更多的 CPU 资源。第二种情况导致变慢的原因在于，Redis 一次需要返回给客户端的数据过多，更多时间花费在数据协议的组装和网络传输过程中。

②操作bigkey

如果查询慢日志发现，并不是复杂度过高的命令导致的，而都是 SET / DEL 这种简单命令出现在慢日志中，那么你就要怀疑实例否写入了 bigkey。

③集中过期

如果发现，平时在操作 Redis 时，并没有延迟很大的情况发生，但在某个时间点突然出现一波延时，其现象表现为：变慢的时间点很有规律，例如某个整点，或者每间隔多久就会发生一波延迟。如果是出现这种情况，那么你需要排查一下，业务代码中是否存在设置大量 key 集中过期的情况。
如果有大量的 key 在某个固定时间点集中过期，在这个时间点访问 Redis 时，就有可能导致延时变大。
一般集中过期使用的是 expireat / pexpireat 命令，需要在代码中搜索这个关键字。

# 实例上限maxmory
在Redis中，是支持给实例设置内存上限的，在当做缓存使用的场景下，一般会设置此值，同时会设置数据淘汰策略，那么就有可能导致Redis变慢。

原因在于当Redis内存使用达到了设置的maxmemory值，因内存中没哟空间写入新的数据，每次进行数据写入之前，都必须先将内存中的一部分数据淘汰出来。数据淘汰出内存，是需要消耗时间的，消耗时间的长短，取决于当前Redis实例的淘汰策略。

现在Redis有八种淘汰策略，分别是：allkeys-lru、volatile-lru、allkeys-random、volatile-random、allkeys-ttl、noeviction（默认）、allkeys-lfu、volatile-lfu。具体使用哪种策略，需要根据具体的业务场景来决定。较为常用的是 allkeys-lru / volatile-lru，即从实例中随机取出一批 key，然后淘汰掉一个最少访问的key，然后取下一批key与之前的key比较，淘汰掉最少访问的key，接着重复以上步骤，直至内存使用将至maxmomey一下。

# fork耗时长
为了保证Redis的数据安全，根据业务需求，会开启RDB或者AOF rewrite功能。这两个功能开启之后，在执行时，主进程会创建一个子进程进行数据的持久化。在创建子进程的过程中，会调用到系统的fork函数，在fork过程中，主进程需要拷贝自己的内存页表给子进程，如果实例较大，拷贝的过程就越久；并且fork过程会消耗大量的cpu资源，fork执行期间，Redis实例无法响应客户端的请求。

可以通过info命令查看 latest_fork_usec项（微秒），这是参数显示了主进程在 fork 子进程期间，整个实例阻塞无法处理客户端请求的时间。可以根据这个参数判断实例无法响应客户端请求的时间长短。

# 内存大页
如果系统开启了内存大页机制，会允许应用程序以2M为单位申请内存，而常规来说，一般是以4k为单位申请的。内存页申请的大小变大了，那么耗时也就增加了。在fork函数执行完成之后，主进程就可以接受客户端的请求了，但此时采用的是写时复制来操作内存数据。写时复制是需要申请新的内存来存放数据，如果开启了大页，就算客户端只修改1k的数据，Redis也会以2M为单位向操作系统申请内存，耗时就会增加，从而导致延迟，影响性能。

# AOF
Redis支持AOF进行数据的持久化，在开启了AOF功能后，Redis会把执行后的写命令写入到AOF文件内存中，然后再根据配置的AOF刷盘策略，把AOF内存数据刷到磁盘上。Redis提供了以下三种策略：
- appendfsync always：主线程每次执行写操作之后立即刷盘，优点是数据安全性高，缺点是会占用大量的磁盘IO；
- appendfsync no：主线程每次写数据只写内存就返回，数据刷盘交给操作系统觉得，优点是对性能的影响最小，但数据安全性最低，宕机丢失的数据取决于系统刷盘时机；
- appendfsync everysec：主线程每次写数据只写内存就返回，后台线程每1秒执行一次刷盘，相当于前两种策略的折中方案，最多丢失1秒的数据。

# Redis运用场景总结
1、缓存 

2、分布式锁 

3、消息队列 

4、全局ID、计数器

基于incrby命令实现原子性的递增

     场景：分布式序列号生成（分库分表）、秒杀、限制接口请求数、限制接口调用次数、限制手机信息发送条数、文章阅读数、点赞数等

5、排行榜

      基于sortedset进行热点数据的排序
      场景：点赞排行榜、热度排行榜等各类需要排序的榜单

6、其他使用场景：购物车、限流、位统计、抽奖、点赞、好友关系、签到打卡、推荐模型等

# 内存碎片
在使用Redis的过程中，有时会发现一个现象：在使用过过程中，为了释放内存，会对Redis中存放的数据进行删除，在删除大量数据后，使用top命令查看时，会发现Redis占用了大量的内存。

造成这个现象的原因是，当数据删除后，Redis释放的内存空间会由内存分配器管理，不会立即将空间返回给操作系统。那么，在操作系统看来，Redis还是占用了大量的内存。

因为被Redis删除的数据在内存中的位置极大概率并不是连续的，那么这些不连续的空间在后续可能会处于一种闲置的状态。并且每个数据所占用的空间大小不一，会导致Redis虽然有空间但是却无法用来保存数据。那么，会导致Redis的内存使用率会降低，同时也会降低Redis运行机器的成本回报率。这种闲置状态的内存，虽然从理论上来看，是可以存储数据的，但实际上因为空间的不连续无法进程存储，这种状态的内存空间，称之为内存碎片。

内存碎片的形成大致分为两种：

一是：内存分配器的分配策略。一般内存分配器是按固定大小进行分配的，并不是完全按照应用程序申请的内存空间大小给程序分配。Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用jemalloc。

jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。

这样的分配方式本身是为了减少分配次数。例如，Redis 申请一个 20 字节的空间保存数据，jemalloc 就会分配 32 字节，此时，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了，因为刚才分配的 32 字节已经够用了，这就避免了一次分配操作。

但是，如果 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好与第二点原因息息相关。

二是：键值对大小不一和删改操作。在不同的业务中操作的键值对可能不一样，那么申请内存空间分配时，申请的大小就不一样。因为内存分配器是按固定大小分配内存的，那么无论是申请空间大于还是小于这个值，只要不是键值对不是固定空间大小的整数倍，都会造成一定的碎片。再则，已经存储的键值对在后续的业务中，也有可能被删除或者修改，可能就会导致空间的额外占用或者释放，也会造成碎片。

那么，一旦大量的内存水片存在，Redis的内存实际利用率就会降低。对于内存数据库，内存利用率直接影响数据库运行效率，为了能监控到内存的使用情况，可以通过Redis自身的INFO命令来进行查看具体信息。
```
>INFO memory
# Memory
used_memory:4997764624
used_memory_human:4.65G
used_memory_rss:5314207744
used_memory_rss_human:4.95G
…
mem_fragmentation_ratio:1.06
```
mem_fragmentation_ratio就是Redis当前的内存碎片率。它是由used_memory_rss（操作系统实际分配空间）/used_memory（Redis实际申请空间）得到的。一般情况下，1<mem_fragmentation_ratio<1.5这个区间是合理的，因为前文提到的两点因素是不可避免的的。但mem_fragmentation_ratio>1.5时，那么就代表内存碎片率超过50%了，那么就需要尽快清理内存碎片了。

内存碎片的清理，最直观的是可以通过重启Redis实现，但重启可能会导致数据丢失（未开启持久化），或者加载数据时间耗费太久影响使用（AOF/RDB过大）。还有一种方法，从Redis 4.0版本开始，Redis本身提供了一种内存碎片自动清理的办法，即将内存中的数据拷贝存放在一起，将之前不连续的空间释放变成连续空间。需要注意的是，碎片的整理也是有代价的，在整理过程中进行数据拷贝是在主线程中进行，那么意味着其他命令的响应可能会有延迟。为了降低带来的性能影响，Redis可以通过activedefrag参数控制是否开启自动清理功能，并且通过active-defrag-ignore-bytes和active-defrag-threshold-lower来设置自动触发阈值，只有同时满足了才会进行自动清理。同时，通过active-defrag-cycle-min和active-defrag-cycle-max来限制CPU资源的使用，尽量减少碎片清理带来的请求处理的延迟。

# 数据倾斜
Redis Cluster集群中，数据会按照一定的分布规则分散到不同的实例上保存，数据都会先按照 CRC16 算法的计算值对 Slot（逻辑槽）取模，同时，所有的 Slot 又会由运维管理员分配到不同的实例上。

当数据量倾斜发生时，数据在切片集群的多个实例上分布不均衡，大量数据集中到了一个或几个实例上。这主要有三个原因，分别是某个实例上保存了bigkey、Slot 分配不均衡以及 Hash Tag。

# 缓存污染
所谓的缓存污染，就是在一些特定的场景下，有些数据被放入缓存中使用，后续就很少使用或者不再使用，这部分数据一直留在内存中占用空间，称之为缓存污染。

要解决缓存污染，我们也能很容易想到解决方案，那就是得把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。

# bigkeys 分析
在 Redis 中，--bigkeys 是 redis-cli 提供的一个选项，用于查找并显示数据库中最大的键。但它没有直接提供一个参数来显示大于某个特定大小（如1M）的键。
```
./redis-cli -p 6400 -a Mall6#te --bigkeys
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.

# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).

[00.00%] Biggest string found so far '"MALL:GOODS:SKU_STOCK:SKU1785131576955240448"' with 3 bytes
[00.00%] Biggest string found so far '"MALL:CONTENT:BIZ_ARGS_CONFIG:GOODS_FOOTPRINT_QUANTITY"' with 302 bytes
[00.00%] Biggest string found so far '"MALL:PAYMENT:SIMULAR_THIRD_PAY:ALI_PC-\xe6\x94\xaf\xe4\xbb\x98\xe5\xae\x9d-PC\xe7\xbd\x91\xe7\xab\x99\xe6\x94\xaf\xe4\xbb\x981806503851088412672"' with 1318 bytes
[00.00%] Biggest string found so far '"MALL:ORDER:SETTLE:1808058301443735552"' with 5960 bytes
[00.00%] Biggest string found so far '"MALL:ORDER:SHOP_CART:M1772862707532300288"' with 6251 bytes

-------- summary -------

Sampled 59 keys in the keyspace!
Total key length in bytes is 2759 (avg len 46.76)

Biggest string found '"MALL:ORDER:SHOP_CART:M1772862707532300288"' has 6251 bytes

0 lists with 0 items (00.00% of keys, avg size 0.00)
0 hashs with 0 fields (00.00% of keys, avg size 0.00)
59 strings with 33817 bytes (100.00% of keys, avg size 573.17)
0 streams with 0 entries (00.00% of keys, avg size 0.00)
0 sets with 0 members (00.00% of keys, avg size 0.00)
0 zsets with 0 members (00.00% of keys, avg size 0.00)
```

# 缓存淘汰策略
## 备份恢复之AOF
Redis在AOF中设置了数据刷盘的控制机制，通过appendfsync参数进行控制，有三种值可选：
- ALWAYS：同步写入，每个写命令执行完立马同步将日志写回磁盘；
- EVERYSEC：每秒写入，每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
- NO：操作系统控制的写回，每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

AOF的写入是以命令追加的形式，也就意味着AOF文件大小会越来越大，文件越大占用的空间就越大，用来恢复的时间就会越长。为了兼顾数据存储与效率，AOF重写机制应运而生。

AOF重写是将旧文件中的多条命令，合并成最新的一条数据操作命令。在恢复时，仅需执行最新的命令即可。

AOF重写是由后台线程bgrewriteaof来完成，意味着不会阻塞主线程。

## 备份恢复之RDB
除了AOF备份，Redis还提供了另外一种数据持久化方案：RDB内存快照，即保存内存中的数据在某一个时刻的状态。

在发生故障或者宕机的时候，可以通过持久化的RDB文件进行数据恢复。但需要注意的是，RDB记载的是某一时刻的数据，而不是数据的操作命令，就意味着仅能恢复到快照那一刻的数据。

Redis提供了save和bgsave两个命令来生成RDB文件，save是在主线程中执行，会导致阻塞；bgsave会创建一个子进程。专门用于RDB文件，避免了主线程的的阻塞，是Redis的默认配置。

虽然bgsave操作可以避免阻塞主线程，但是备份期间能不能进行正常的写操作也很重要。在快照期间，为了保持快照的完整性，一般都是可以读，不能修改。

为了快照备份而暂时不能写，对弈Redis来说，是不可以接受的。为了解决这个问题，Redis借助了操作系统提供的写时复制技术（COW），在执行快照的同事，也可以处理写操作。

# Redis数据同步方案
Redis-shake是阿里云Redis&MongoDB团队开源的用于redis数据同步的工具。

基本原理

Redis-shake的基本原理就是模拟一个从节点加入源redis集群，首先进行全量拉取并回放，然后进行增量的拉取（通过psync命令）

# proxy支持
# Redis 跨机房双向同步
1.	商业版支持该功能
2.	携程开源的https://github.com/ctripcorp/x-pipe

