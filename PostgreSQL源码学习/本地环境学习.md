- [架构](#架构)
- [查看所有参数](#查看所有参数)
- [查看主库复制状态](#查看主库复制状态)
- [查看从库复制状态](#查看从库复制状态)
- [其它方式确认主从关系](#其它方式确认主从关系)
- [设置从库延迟时间](#设置从库延迟时间)
- [复制槽](#复制槽)
- [explain](#explain)
  - [节点类型](#节点类型)
  - [扫描节点](#扫描节点)
    - [Seq Scan](#seq-scan)
    - [Index Scan](#index-scan)
    - [IndexOnly Scan](#indexonly-scan)
    - [BitmapIndex Scan 与BitmapHeap Scan](#bitmapindex-scan-与bitmapheap-scan)
  - [代价估计信息](#代价估计信息)
  - [真实执行信息](#真实执行信息)
  - [单表访问](#单表访问)
  - [多表连接](#多表连接)
  - [集合运算](#集合运算)
  - [排序分组](#排序分组)
  - [限制结果](#限制结果)
  - [访问谓词与过滤谓词](#访问谓词与过滤谓词)
  - [EXPLAIN 语句的完整语法](#explain-语句的完整语法)
    - [ANALYZE](#analyze)
    - [VERBOSE](#verbose)
    - [COSTS](#costs)
    - [SETTINGS](#settings)
    - [GENERIC\_PLAN](#generic_plan)
    - [BUFFERS](#buffers)
    - [WAL](#wal)
    - [TIMING](#timing)
    - [SUMMARY](#summary)
    - [FORMAT](#format)
- [数据膨胀例行清理](#数据膨胀例行清理)
  - [原理](#原理)
  - [监控](#监控)
  - [调优](#调优)
- [磁盘空间的可能问题](#磁盘空间的可能问题)
  - [长时间的Query](#长时间的query)
  - [废弃的replication slots](#废弃的replication-slots)
  - [僵死或处于孤儿状态的 prepared transaction](#僵死或处于孤儿状态的-prepared-transaction)
- [PostgreSQL的元组、页面结构及索引查找原理](#postgresql的元组页面结构及索引查找原理)
  - [元组结构](#元组结构)
  - [更新过程](#更新过程)
  - [删除过程](#删除过程)
  - [页面结构](#页面结构)
  - [索引查找](#索引查找)
- [PostgreSQL逻辑复制--常见坑点](#postgresql逻辑复制--常见坑点)
  - [坑点1: 磁盘空间耗尽](#坑点1-磁盘空间耗尽)
  - [坑点2: CPU Usage太高](#坑点2-cpu-usage太高)
  - [坑点3: 同步延迟较大](#坑点3-同步延迟较大)
- [如何杀掉pg数据库正在运行的sql](#如何杀掉pg数据库正在运行的sql)
- [查看当前库有哪些 schema](#查看当前库有哪些-schema)
- [freeze 机制](#freeze-机制)
    - [Freeze 机制的工作原理](#freeze-机制的工作原理)
    - [为什么需要冻结](#为什么需要冻结)
    - [资源消耗](#资源消耗)
- [事务号回卷问题](#事务号回卷问题)
  - [可见性映射VM](#可见性映射vm)
  - [冻结过程FREEZE](#冻结过程freeze)
  - [最佳实践](#最佳实践)
- [Oracle、MySQL、PG是如何处理数据库“半页写”的问题的](#oraclemysqlpg是如何处理数据库半页写的问题的)

# 架构
```
patronictl -c /etc/patroni.yml list
+ Cluster: yace_pgsql --+--------------+-----------+----+-----------+
| Member | Host         | Role         | State     | TL | Lag in MB |
+--------+--------------+--------------+-----------+----+-----------+
| pg01   | 172.16.13.74 | Leader       | running   | 14 |           |
| pg02   | 172.16.13.75 | Replica      | streaming | 14 |         0 |
| pg03   | 172.16.13.76 | Sync Standby | streaming | 14 |         0 |
+--------+--------------+--------------+-----------+----+-----------+
```
# 查看所有参数
```sql
\d pg_settings;
               View "pg_catalog.pg_settings"
     Column      |  Type   | Collation | Nullable | Default 
-----------------+---------+-----------+----------+---------
 name            | text    |           |          | 
 setting         | text    |           |          | 
 unit            | text    |           |          | 
 category        | text    |           |          | 
 short_desc      | text    |           |          | 
 extra_desc      | text    |           |          | 
 context         | text    |           |          | 
 vartype         | text    |           |          | 
 source          | text    |           |          | 
 min_val         | text    |           |          | 
 max_val         | text    |           |          | 
 enumvals        | text[]  |           |          | 
 boot_val        | text    |           |          | 
 reset_val       | text    |           |          | 
 sourcefile      | text    |           |          | 
 sourceline      | integer |           |          | 
 pending_restart | boolean |           |          | 


select
   name,setting,unit,category,short_desc,context,vartype,source,min_val,max_val,enumvals,
   boot_val,reset_val,sourcefile,sourceline,pending_restart 
from pg_settings 
order by category,name
```

# 查看主库复制状态
```sql
postgres=# \x
Expanded display is on.
postgres=# select * from pg_stat_replication;
-[ RECORD 1 ]----+------------------------------
pid              | 68490
usesysid         | 16384
usename          | repl
application_name | pg03
client_addr      | 172.16.13.76
client_hostname  | 
client_port      | 35334
backend_start    | 2024-07-01 11:55:02.163443+08
backend_xmin     | 
state            | streaming
sent_lsn         | 3/5F000338
write_lsn        | 3/5F000338
flush_lsn        | 3/5F000338
replay_lsn       | 3/5F000338
write_lag        | 
flush_lag        | 
replay_lag       | 
sync_priority    | 1
sync_state       | sync
reply_time       | 2024-07-18 11:48:43.200432+08
-[ RECORD 2 ]----+------------------------------
pid              | 70857
usesysid         | 16384
usename          | repl
application_name | pg02
client_addr      | 172.16.13.75
client_hostname  | 
client_port      | 33816
backend_start    | 2024-07-01 15:01:03.998514+08
backend_xmin     | 
state            | streaming
sent_lsn         | 3/5F000338
write_lsn        | 3/5F000338
flush_lsn        | 3/5F000338
replay_lsn       | 3/5F000338
write_lag        | 
flush_lag        | 
replay_lag       | 
sync_priority    | 0
sync_state       | async
reply_time       | 2024-07-18 11:48:41.994551+08
```

1. **sent_lsn**: 主库发送到从库的最后一个 WAL 位置。这表示主库已经发送但从库可能还没有写入的 WAL 位置。
2. **write_lsn**: 从库写入操作系统缓存的最后一个 WAL 位置。这表示 WAL 已经到达从库并写入操作系统缓存，但还没有刷新到磁盘。
3. **flush_lsn**: 从库刷新到磁盘的最后一个 WAL 位置。这表示 WAL 已经持久化到从库的磁盘上。
4. **replay_lsn**: 从库重放的最后一个 WAL 位置。这表示从库已经应用的 WAL 位置，用户可以看到这些更改。

查看当前 lsn
```sql
postgres=# \x
Expanded display is off.
postgres=# SELECT pg_current_wal_lsn();                 
 pg_current_wal_lsn 
--------------------
 3/5F000338
(1 row)

postgres=# SELECT pg_walfile_name(pg_current_wal_lsn());
     pg_walfile_name      
--------------------------
 0000000E000000030000005F
(1 row)
```

# 查看从库复制状态
```sql
SELECT * FROM pg_stat_wal_receiver;
-[ RECORD 1 ]---------+---------------------------------------------------------------------------------------------------------------------------------------------------
pid                   | 1488
status                | streaming
receive_start_lsn     | 3/5F000000
receive_start_tli     | 14
written_lsn           | 3/5F000338
flushed_lsn           | 3/5F000338
received_tli          | 14
last_msg_send_time    | 2024-07-18 11:55:33.239685+08
last_msg_receipt_time | 2024-07-18 11:55:33.240113+08
latest_end_lsn        | 3/5F000338
latest_end_time       | 2024-07-01 15:01:14.007753+08
slot_name             | pg02
sender_host           | 172.16.13.74
sender_port           | 5432
conninfo              | user=repl passfile=/home/postgres/pgpass host=172.16.13.74 port=5432 sslmode=prefer application_name=pg02 gssencmode=prefer channel_binding=prefer
```

# 其它方式确认主从关系
通过 pg_is_in_recovery() 查看主从
```sql
-- 主库
select pg_is_in_recovery();
 pg_is_in_recovery 
-------------------
 f

-- 从库
select pg_is_in_recovery();
 pg_is_in_recovery 
-------------------
 t
```

通过 pg_controldata 判断
```sh
/data/pgsql/13/bin/pg_controldata /data/pgsql/13/data/ | grep cluster
Database cluster state:               in production
```

# 设置从库延迟时间
```sql
recovery_min_apply_delay = 30min
```

# 复制槽
主库的事务日志一直处于滚动消耗的状态，如果备库下线，随着主库频繁的数据变动，可能就会存在当备库重新上线后，已经找不到之前没有拉取的事务日志的情况（被主库回收掉了）。
但是有了复制槽，主库就会为复制槽保留它没有消费的日志，等待它上线后进行消费。当然代价是对磁盘的消耗，不过只要备库不是永久丢失，磁盘消耗对于大部分场景来说不是问题。
但是如果备库永久丢失了，要记得删除主库中对应的复制槽。删除复制槽的语句为
```sql
select pg_drop_replication_slot('pgstandby1');
```

在主库查看复制槽
```sql
select * from pg_replication_slots;

-[ RECORD 1 ]-------+-----------
slot_name           | pg03
plugin              | 
slot_type           | physical
datoid              | 
database            | 
temporary           | f
active              | t
active_pid          | 68490
xmin                | 
catalog_xmin        | 
restart_lsn         | 3/5F000338
confirmed_flush_lsn | 
wal_status          | reserved
safe_wal_size       | 
-[ RECORD 2 ]-------+-----------
slot_name           | pg02
plugin              | 
slot_type           | physical
datoid              | 
database            | 
temporary           | f
active              | t
active_pid          | 70857
xmin                | 
catalog_xmin        | 
restart_lsn         | 3/5F000338
confirmed_flush_lsn | 
wal_status          | reserved
safe_wal_size       | 
```

手动把备库提升为主库  
一旦主库挂掉，并且已知备库的数据足够完整的情况下，我们可以迅速把备库提升为主库。只要找到备库的文件路径，把里面的standby.signal文件删除即可。顺便说一下，这个文件是没有内容的，它是一个空文件，通过这个文件的存在来表明自己是个备库，所以删掉或者重命名该文件，都能把这个备库提升为主库。当然，别忘了删除该文件后，重启备库才能生效。

# explain
```sql
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 < 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;
 
                                                                 QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------
 Sort  (cost=717.34..717.59 rows=101 width=488) (actual time=7.761..7.774 rows=100 loops=1)
   Sort Key: t1.fivethous
   Sort Method: quicksort  Memory: 77kB
   ->  Hash Join  (cost=230.47..713.98 rows=101 width=488) (actual time=0.711..7.427 rows=100 loops=1)
         Hash Cond: (t2.unique2 = t1.unique2)
         ->  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244) (actual time=0.007..2.583 rows=10000 loops=1)
         ->  Hash  (cost=229.20..229.20 rows=101 width=244) (actual time=0.659..0.659 rows=100 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 28kB
               ->  Bitmap Heap Scan on tenk1 t1  (cost=5.07..229.20 rows=101 width=244) (actual time=0.080..0.526 rows=100 loops=1)
                     Recheck Cond: (unique1 < 100)
                     ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0) (actual time=0.049..0.049 rows=100 loops=1)
                           Index Cond: (unique1 < 100)
 Planning time: 0.194 ms
 Execution time: 8.008 ms
 ```
 简化结构
```sql
Sort
└── Hash Join
    ├── Seq Scan
    └── Hash
        └── Bitmap Heap Scan
            └── Bitmap Index Scan
```

- 按照查询计划树从底往上执行
- 基于火山模型（参考文档火山模型介绍）执行，即可以简单理解为每个节点执行返回一行记录给父节点（Bitmap Index Scan 除外）

## 节点类型
    控制节点（Control Node)
    扫描节点（ScanNode)
    物化节点（Materialization Node)
    连接节点（Join Node)
## 扫描节点
扫描节点，简单来说就是为了扫描表的元组，每次获取一条元组（Bitmap Index Scan除外）作为上层节点的输入。当然严格的说，不光可以扫描表，还可以扫描函数的结果集、链表结构、子查询结果集等。

目前在PostgreSQL 中支持：

- Seq Scan，顺序扫描
- Index Scan，基于索引扫描，但不只是返回索引列的值
- IndexOnly Scan，基于索引扫描，并且只返回索引列的值，简称为覆盖索引
- BitmapIndex Scan，利用Bitmap 结构扫描
- BitmapHeap Scan，把BitmapIndex Scan 返回的Bitmap 结构转换为元组结构
- Tid Scan，用于扫描一个元组TID 数组
- Subquery Scan，扫描一个子查询
- Function Scan，处理含有函数的扫描
- TableFunc Scan，处理tablefunc 相关的扫描
- Values Scan，用于扫描Values 链表的扫描
- Cte Scan，用于扫描WITH 字句的结果集
- NamedTuplestore Scan，用于某些命名的结果集的扫描
- WorkTable Scan，用于扫描Recursive Union 的中间数据
- Foreign Scan，用于外键扫描
- Custom Scan，用于用户自定义的扫描

最常用的几个：Seq Scan、Index Scan、IndexOnly Scan、BitmapIndex Scan、BitmapHeap Scan

### Seq Scan
Seq Scan 是全表顺序扫描，一般查询没有索引的表需要全表顺序扫描，例如下面的EXPLAIN 输出：
```sql
postgres=> explain(ANALYZE,VERBOSE,BUFFERS) select * from class where st_no=2;
                                               QUERY PLAN
--------------------------------------------------------------------------------------------------------
 Seq Scan on public.class  (cost=0.00..26.00 rows=1 width=35) (actual time=0.136..0.141 rows=1 loops=1)
   Output: st_no, name
   Filter: (class.st_no = 2)
   Rows Removed by Filter: 1199
   Buffers: shared hit=11
 Planning time: 0.066 ms
 Execution time: 0.160 ms
 ```
 其中：
- Seq Scan on public.class 表明了这个节点的类型和作用对象，即在class 表上进行了全表扫描
- (cost=0.00..26.00 rows=1 width=35) 表明了这个节点的代价估计，这部分我们将在下文节点代价估计信息中详细介绍
- (actual time=0.136..0.141 rows=1 loops=1) 表明了这个节点的真实执行信息，当EXPLAIN 命令中的ANALYZE选项为on时，会输出该项内容，具体的含义我们将在下文节- 执行信息中详细介绍
- Output: st_no, name 表明了SQL 的输出结果集的各个列，当EXPLAIN 命令中的选项VERBOSE 为on时才会显示
- Filter: (class.st_no = 2) 表明了Seq Scan 节点之上的Filter 操作，即全表扫描时对每行记录进行过滤操作，过滤条件为class.st_no = 2
- Rows Removed by Filter: 1199 表明了过滤操作过滤了多少行记录，属于Seq Scan 节点的VERBOSE 信息，只有EXPLAIN 命令中的VERBOSE 选项为on 时才会显示
- Buffers: shared hit=11 表明了从共享缓存中命中了11 个BLOCK，属于Seq Scan 节点的BUFFERS 信息，只有EXPLAIN 命令中的BUFFERS 选项为on 时才会显示
- Planning time: 0.066 ms 表明了生成查询计划的时间
- Execution time: 0.160 ms 表明了实际的SQL 执行时间，其中不包括查询计划的生成时间

### Index Scan
Index Scan 是索引扫描，主要用来在WHERE 条件中存在索引列时的扫描，如上面Seq Scan 中的查询如果在st_no 上创建索引，则EXPLAIN 输出如下：
```sql
postgres=> explain(ANALYZE,VERBOSE,BUFFERS) select * from class where st_no=2;
                                                       QUERY PLAN
------------------------------------------------------------------------------------------------------------------------
 Index Scan using no_index on public.class  (cost=0.28..8.29 rows=1 width=35) (actual time=0.022..0.023 rows=1 loops=1)
   Output: st_no, name
   Index Cond: (class.st_no = 2)
   Buffers: shared hit=3
 Planning time: 0.119 ms
 Execution time: 0.060 ms
(6 rows)
```
其中：
- Index Scan using no_index on public.class 表明是使用的public.class 表的no_index 索引对表进行索引扫描的
- Index Cond: (class.st_no = 2) 表明索引扫描的条件是class.st_no = 2

### IndexOnly Scan
IndexOnly Scan 是覆盖索引扫描，所需的返回结果能被所扫描的索引全部覆盖，例如上面Index Scan中的SQL 把“select * ” 修改为“select st_no” ，其EXPLAIN 结果输出如下：
```sql
postgres=> explain(ANALYZE,VERBOSE,BUFFERS) select st_no from class where st_no=2;
                                                         QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------
 Index Only Scan using no_index on public.class  (cost=0.28..4.29 rows=1 width=4) (actual time=0.015..0.016 rows=1 loops=1)
   Output: st_no
   Index Cond: (class.st_no = 2)
   Heap Fetches: 0
   Buffers: shared hit=3
 Planning time: 0.058 ms
 Execution time: 0.036 ms
(7 rows)
```
其中：
- Index Only Scan using no_index on public.class 表明使用public.class 表的no_index 索引对表进行覆盖索引扫描
- Heap Fetches 表明需要扫描数据块的个数。

虽然Index Only Scan 可以从索引直接输出结果。但是因为PostgreSQL MVCC 机制的实现，需要对扫描的元组进行可见性判断，即检查visibility MAP 文件。当新建表之后，如果没有进行过vacuum和autovacuum操作，这时还没有VM文件，而索引并没有保存记录的版本信息，索引Index Only Scan 还是需要扫描数据块（Heap Fetches 代表需要扫描的数据块个数）来获取版本信息，这个时候可能会比Index Scan 慢。

### BitmapIndex Scan 与BitmapHeap Scan
BitmapIndex Scan 与Index Scan 很相似，都是基于索引的扫描，但是BitmapIndex Scan 节点每次执行返回的是一个位图而不是一个元组，其中位图中每位代表了一个扫描到的数据块。而BitmapHeap Scan一般会作为BitmapIndex Scan 的父节点，将BitmapIndex Scan 返回的位图转换为对应的元组。这样做最大的好处就是把Index Scan 的随机读转换成了按照数据块的物理顺序读取，在数据量比较大的时候，这会大大提升扫描的性能。

我们可以运行set enable_indexscan =off; 来指定关闭Index Scan ，上文中Index Scan 中SQL 的EXPLAIN 输出结果则变为：
```sql
postgres=> explain(ANALYZE,VERBOSE,BUFFERS) select * from class where st_no=2;
                                                   QUERY PLAN
-----------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on public.class  (cost=4.29..8.30 rows=1 width=35) (actual time=0.025..0.025 rows=1 loops=1)
   Output: st_no, name
   Recheck Cond: (class.st_no = 2)
   Heap Blocks: exact=1
   Buffers: shared hit=3
   ->  Bitmap Index Scan on no_index  (cost=0.00..4.29 rows=1 width=0) (actual time=0.019..0.019 rows=1 loops=1)
         Index Cond: (class.st_no = 2)
         Buffers: shared hit=2
 Planning time: 0.088 ms
 Execution time: 0.063 ms
(10 rows)
```
其中：
- Bitmap Index Scan on no_index 表明使用no_index 索引进行位图索引扫描
- Index Cond: (class.st_no = 2) 表明位图索引的条件为class.st_no = 2
- Bitmap Heap Scan on public.class 表明对public.class 表进行Bitmap Heap 扫描
- Recheck Cond: (class.st_no = 2) 表明Bitmap Heap Scan 的Recheck操作 的条件是class.st_no = 2，这是因为Bitmap Index Scan 节点返回的是位图，位图中每位- 表了一个扫描到的数据块，通过位图可以定位到一些符合条件的数据块（这里是3，Buffers: shared hit=3），而Bitmap Heap Scan 则需要对每个数据块的元组进行Recheck
- Heap Blocks: exact=1 表明准确扫描到数据块的个数是1

至此，我们对这几种主要的扫描节点有了一些认识。一般来说：

 - 大多数情况下，Index Scan 要比 Seq Scan 快。但是如果获取的结果集占所有数据的比重很大时，这时Index Scan 因为要先扫描索引再读表数据反而不如直接全表扫描来- 快。
 - 如果获取的结果集的占比比较小，但是元组数很多时，可能Bitmap Index Scan 的性能要比Index Scan 好。
 - 如果获取的结果集能够被索引覆盖，则Index Only Scan 因为不用去读数据，只扫描索引，性能一般最好。但是如果VM 文件未生成，可能性能就会比Index Scan 要差。

上面的结论都是基于理论分析得到的结果，但是其实PostgreSQL 的EXPLAIN 命令中输出的cost，rows，width 等代价估计信息中已经展示了这些扫描节点或者其他节点的预估代价，通过对预估代价的比较，可以选择出最小代价的查询计划树。

## 代价估计信息
从上文可知，EXPLAIN 命令会在每个节点后面显示代价估计信息，包括cost、rows、width，这里将一一介绍。

在PostgreSQL 中，执行优化器会基于代价估计自动选择代价最小的查询计划树。而在EXPLAIN 命令的输出结果中每个cost 就是该执行节点的代价估计。它的格式是xxx..xxx，在.. 之前的是预估的启动代价，即找到符合该节点条件的第一个结果预估所需要的代价，在..之后的是预估的总代价。而父节点的启动代价包含子节点的总代价。

而在本文开头讲述PostgreSQL DBA 对慢SQL 的常见诊断方法就是使用EXPLAIN 命令，分析其中哪个节点cost （或者下文的 actual time ）最大，通过快速优化它达到优化慢SQL 的目的。

那cost 是怎么计算而来的呢？简单来说，是PostgreSQL 根据周期性收集到的统计信息（参考PostgreSQL · 特性分析 · 统计信息计算方法），按照一个代价估计模型计算而来的。其中会根据以下几个参数来作为代价估计的单位（详见PostgreSQL 官方文档）：
- seq_page_cost
- random_page_cost
- cpu_tuple_cost
- cpu_index_tuple_cost
- cpu_operator_cost
- parallel_setup_cost
- parallel_tuple_cost

其中，seq_page_cost 和random_page_cost 可以使用ALTER TABLESPACE 对每个TABLESPACE 进行修改。

代价估计信息中的其他两个，rows 代表预估的行数，width 代表预估的结果宽度，单位为字节。两者都是根据表的统计信息预估而来的。

## 真实执行信息
当EXPLAIN 命令中ANALYZE 选项为on时，会在代价估计信息之后输出真实执行信息，包括：

- actual time 执行时间，格式为xxx..xxx，在.. 之前的是该节点实际的启动时间，即找到符合该节点条件的第一个结果实际需要的时间，在..之后的是该节点实际的执行时间
- rows 指的是该节点实际的返回行数
- loops 指的是该节点实际的重启次数。如果一个计划节点在运行过程中，它的相关参数值（如绑定变量）发生了变化，就需要重新运行这个计划节点。

这里需要注意的是，代价估计信息一般是和真实执行信息比较相近的，即预估代价和实际时间成正比且返回结果集的行数相近。但是由于统计信息的时效性，有可能找到的预估代价最小的性能却很差，这就需要开发者调整参数或者主动执行vacuum analyze 命令对表的统计信息进行及时更新，保证PostgreSQL 的执行优化器能够找到相对较优的查询计划树。

## 单表访问
- 顺序扫描（适用于返回大部分数据行）
- 索引扫描（适用于返回很少数据行）
- 位图索引扫描（适用于返回较多数据行）
## 多表连接
- 嵌套循环（Nested Loop）
- 哈希连接（Hash Join）
- 排序合并（Merge Join）
## 集合运算
UNION、INTERSECT、EXCEPT
## 排序分组
排序（ORDER BY）和分组（GROUP BY）
## 限制结果
Top-N 查询和分页查询
## 访问谓词与过滤谓词
对于 WHERE 子句（谓词），PostgreSQL 提供了三种不同的实现方法：
- 索引访问谓词
- 索引过滤谓词
- 表级过滤谓词
## EXPLAIN 语句的完整语法
```sql
EXPLAIN [ ( option [, ...] ) ] statement
EXPLAIN [ ANALYZE ] [ VERBOSE ] statement

其中 option 可以为以下选项之一:

    ANALYZE [ boolean ]
    VERBOSE [ boolean ]
    COSTS [ boolean ]
    SETTINGS [ boolean ]
    GENERIC_PLAN [ boolean ]
    BUFFERS [ boolean ]
    WAL [ boolean ]
    TIMING [ boolean ]
    SUMMARY [ boolean ]
    FORMAT { TEXT | XML | JSON | YAML }
```
其中，ANALYZE 和 VERBOSE 选项支持两种指定方法；其他选项需要使用括号包含，多个选项使用逗号进行分隔。

statement 可以是以下语句之一：SELECT、INSERT、UPDATE、DELETE、MERGE、VALUES、EXECUTE、DECLARE、CREATE TABLE AS、CREATE MATERIALIZED VIEW AS。

boolean 用于启用或者禁用相关选项。TRUE、ON 或者 1 表示启用，FALSE、OFF 或者 0 表示禁用。如果忽略了 boolean 设置，默认为启用。

### ANALYZE
ANALYZE 选项不仅显示预估的执行计划，还会实际执行相应的语句，并且返回执行时间和其他信息统计。该选项默认为 FALSE。

一方面，为了测量执行计划中每个节点的执行时成本，当前 EXPLAIN ANALYZE 的实现在执行计划中增加了一些分析开销，因此执行 EXPLAIN ANALYZE 命令有时候会导致查询比正常运行花费的时间明显更长。具体的分析开销取决于查询语句以及数据库运行的平台，有可能查询节点每次执行只需要很短的时间，但是操作系统获取时间的调用反而更慢，可以使用 pg_test_timing 工具测量系统的计时开销。

另一方面， EXPLAIN ANALYZE 不需要将查询结果发送到客户端，因此没有包含网络传输和转换成本。
### VERBOSE

VERBOSE 选项用于在执行计划中显示额外的信息。例如：
```sql
EXPLAIN VERBOSE 
SELECT *
FROM test;

QUERY PLAN                                                        |
------------------------------------------------------------------+
Seq Scan on emerald.test  (cost=0.00..323.00 rows=10000 width=141)|
  Output: id, vc, vn, vd, other                                   |
```
以上 EXPLAIN VERBOSE 显示了顺序扫描节点输出的字段列表（Output），以及包含模式名限定的表名（emerald.test）。

对于不同的操作节点，VERBOSE 选项还会显示其他额外信息。该选项默认禁用。
### COSTS

COSTS 选项用于输出每个计划节点的预估启动成本和总成本，以及预估行数和平均长度。该选项默认启用。

### SETTINGS

SETTINGS 选项用于显示配置参数，尤其是影响查询计划的非默认设置的参数。该选项默认禁用。例如：
```sql
EXPLAIN (SETTINGS)
SELECT *
FROM test;

QUERY PLAN                                                |
----------------------------------------------------------+
Seq Scan on test  (cost=0.00..323.00 rows=10000 width=141)|
Settings: search_path = 'hrdb, public, "$user"'           |
```
### GENERIC_PLAN
PostgreSQL 16 版本增加了 GENERIC_PLAN 选项，可以为预编译语句 生成通用执行计划，这种执行计划不依赖于绑定变量（例如 $1、$2等）的值。例如：
```sql
EXPLAIN (GENERIC_PLAN)
SELECT *
FROM test
WHERE vn = $1;

QUERY PLAN                                                              |
------------------------------------------------------------------------+
Index Scan using idx_test_vn on test  (cost=0.29..8.30 rows=1 width=141)|
  Index Cond: (vn = $1)    
```
GENERIC_PLAN 选项默认禁用，而且不能和 ANALYZE 选项一起使用，因为 ANALYZE 需要执行语句。

另外，预编译语句也可能使用定制执行计划，也就是使用绑定变量的具体值创建执行计划。例如：
```sql
PREPARE query_test(numeric)
AS 
SELECT *
FROM test
WHERE vn = $1;

EXPLAIN EXECUTE query_test(10);

QUERY PLAN                                                              |
------------------------------------------------------------------------+
Index Scan using idx_test_vn on test  (cost=0.29..8.30 rows=1 width=141)|
  Index Cond: (vn = '10'::numeric)                                                 |


DEALLOCATE query_test;
```
### BUFFERS

BUFFERS 选项用于显示缓冲区使用情况，默认禁用。例如：
```sql
EXPLAIN (ANALYZE, BUFFERS)
SELECT *
FROM test
WHERE id = 1000;

QUERY PLAN                                                                                                      |
----------------------------------------------------------------------------------------------------------------+
Index Scan using test_pkey on test  (cost=0.29..8.30 rows=1 width=141) (actual time=0.030..0.032 rows=1 loops=1)|
  Index Cond: (id = 1000)                                                                                       |
  Buffers: shared hit=3                                                                                         |
Planning Time: 0.266 ms                                                                                         |
Execution Time: 0.071 ms          
```
其中，shared hit 表示共享块命中。

具体来说，BUFFERS 选项显示的信息包括共享内存块命中（hit）、读取（read）、标记脏块（dirtied）以及写入（written）数量，本地内存块命中（hit）、读取（read）、标记脏块（dirtied）以及写入（written）数量，临时内存块的读取（read）和写入（written）数量。如果启用了服务器参数 track_io_timing ，还会显示读写数据文件块和临时文件块的时间（毫秒）。

其中，一次命中意味着避免了一次磁盘读取，因为所需数据块已经存在缓存中。共享内存块包含了普通表和索引的缓存数据，本地内存块包含了临时表和索引的缓存数据；临时内存块包含了排序、哈希、物化节点等操作使用的临时数据。

脏块的数量表示之前未改动，但是当前查询修改的数据块；写入块的数量表示之前被标记为脏块，同时在当前查询处理过程总被后台进程刷新到磁盘的数据块。上层节点显示的数量包含了子节点的数量，对于 TEXT 输出格式，只显示非零数据值。

### WAL

WAL 选项用于显示有关预写式日志记录生成的信息。具体来说，包括记录数、全页镜像数（fpi）以及生成的 WAL（字节）。如果 FORMAT 选项的值为 TEXT（默认值），只显示非零信息。该选项只能在启用 ANALYZE 选项时使用，默认为禁用。

### TIMING

TIMING 选项用于显示每个计划节点的启用时间和完成时间（毫秒），该选项只能在启用 ANALYZE 选项时使用，默认为启用。

某些平台上重复读取系统时间可能会明显影响查询性能，如果只关注实际返回的行数，可以在启用 ANALYZE 选项时将该选项禁用。即使关闭了节点的计时功能，整个语句的运行时间仍然会统计并显示。

### SUMMARY

SUMMARY 选项用于在执行计划之后显示汇总信息（例如总的时间消耗）。如果启用了 ANALYZE 选项，默认显示汇总信息；否则默认不会显示汇总信息。

对于 EXPLAIN EXECUTE 语句，Planning time 包含了从缓存中获取执行计划或者重新计划消耗的时间。

### FORMAT

FORMAT 选项用于指定执行计划的输出格式，可以使用 TEXT、XML、JSON 或者 YAML 格式。默认输出格式为 TEXT，其他格式输出的内容和 TEXT 格式相同，只是更方便程序处理。例如：
```sql
EXPLAIN (FORMAT JSON)
SELECT *
FROM test;

[
  {
    "Plan": {
      "Node Type": "Seq Scan",
      "Parallel Aware": false,
      "Async Capable": false,
      "Relation Name": "test",
      "Alias": "test",
      "Startup Cost": 0.00,
      "Total Cost": 323.00,
      "Plan Rows": 10000,
      "Plan Width": 141
    }
  }
]
```

# 数据膨胀例行清理
分析型数据库 PostgreSQL的堆表使用 PostgreSQL 的多版本并发控制（MVCC）存储实现。被删除或更新的行被从数据库逻辑删除，但是该行的一个不可见映像保留在表中。这些被删除的行（也被称为过期行）被存储在一个空闲空间映射文件中。运行 VACUUM 会把过期行标记为可以被后续插入重用的空闲空间。

如果空闲空间映射不足以容纳所有的过期行，VACUUM 命令就不能从导致空闲空间映射溢出的过期行回收空间。磁盘空间只能通过运行 VACUUM FULL 恢复，这个操作会锁住表，逐行拷贝到文件的开头，然后截断文件。这是一种昂贵的操作，对于大型的表，它可能需要超乎想象的时间来完成，应该只在较小的表上使用这种操作。如果使用者尝试杀死 VACUUM FULL 操作，系统可能会损坏。

注意：在大量的的 UPDATE 以及 DELETE 操作之后非常有必要运行 VACUUM， 这样可以避免运行 VACUUM FULL。
## 原理
![](https://hseagle.github.io/pg_autovacuum_internal.png)

```sql
DROP EXTENSION IF EXISTS pageinspect;
create extension pageinspect;
create table person(name varchar(64), age int);
insert into person values('andrew', 22);
select xmin, xmax, cmin, cmax, * from person;
```
当插入一条记录到PostgreSQL表中，系统字段xmax为0, 如果对应的记录被删除或修改，那么该字段为非0,写入的是执行该操作的transaction id, 借助于pageinspect模块，我们可以看到物理页中的真正内容。

借助于pageinspect, 可以做一个简单试验，看修改记录后，表的物理页中真正的记录形式如何。
```sql
DROP EXTENSION IF EXISTS pageinspect;
create extension pageinspect;
drop table if exists person;
create table person(name varchar(64), age int);
insert into person values('andrew', 24);
SELECT t_xmin, t_xmax, tuple_data_split('person'::regclass, t_data, t_infomask, t_infomask2, t_bits) 
FROM heap_page_items(get_raw_page('person', 0));

  t_xmin  | t_xmax |          tuple_data_split           
----------+--------+-------------------------------------
 39706142 |      0 | {"\\x0f616e64726577","\\x18000000"}

update person set age = 25 where name = 'andrew';

SELECT t_xmin, t_xmax, tuple_data_split('person'::regclass, t_data, t_infomask, t_infomask2, t_bits) 
FROM heap_page_items(get_raw_page('person', 0));
  t_xmin  |  t_xmax  |          tuple_data_split           
----------+----------+-------------------------------------
 39706142 | 39706143 | {"\\x0f616e64726577","\\x18000000"}
 39706143 |        0 | {"\\x0f616e64726577","\\x19000000"}
```
输出结果表明，update操作不会在原有记录上进行修改，而是将原有记录置为无效(xmax设置为非零值)，然后重新写入一条全新记录。

## 监控
查看用户表中垃圾记录的数量，并计算和有效记录的比值。
```sql
select relname, n_live_tup, n_dead_tup, round(n_dead_tup*1.0/n_live_tup, 2) as dead_ratio from pg_stat_user_tables where n_live_tup > 0;

 relname | n_live_tup | n_dead_tup | dead_ratio 
---------+------------+------------+------------
 person  |          1 |          1 |       1.00
```
## 调优
触发autovacuum的条件:  
`pg_stat_user_tables.n_dead_tup > (threshold + pg_class.reltuples * scale_factor)`  
为了尽早触发autovacuum, 可以针对表级别，修改autovacuum配置
```sql
alter table demo set (autovacuum_vacuum_threshold_size=0);
alter table demo set (autovacuum_vacuum_scale_factor=0.02);
```
autovacuum会带来额外的i/o开销，提升系统负载，对数据库系统的稳定性带来潜在影响，所以PostgreSQL针对autovacuum是有相应的限流设置, 相关的参数有两个
```sql
autovacuum_vacuum_cost_delay
autovacuum_vacuum_cost_limit
```
一般不建议更改 autovacuum_vacuum_cost_delay, 可以把默认的 autovacuum_vacuum_cost_limit 更改为大一点的值，允许触发和执行更多的autovacuum活动。

# 磁盘空间的可能问题
## 长时间的Query
如果某些Query运行了很长时间，比如几个小时甚至几天，那么这些Query就会导致autovacuum无法清除垃圾数据。

假设这些查询是在T0时刻启动，在T1时刻，有数据被删除或者更新，在T2时刻，autovacuum开始进行清理，在这个新启动的清除过程中，只有T0时刻之前的dead tuples会被有效清理，而在T1时刻被删除的数据无法被清除，因为T0时刻的查询依然需要这些数据。

要解决这个问题，就必须终止长时间的query。一种是等查询自然完成，另一种是显式的kill, 假设某query的pid是123, 那么使用 pg_terminate_backend 或 pg_cancel_backend
```sql
select pg_terminate_backend(query_pid)
```

## 废弃的replication slots
如果某些subscriptor订阅了CDC消息，但是subscriber异常退出后，并没有删除对应的replication slots，那么由于数据没有被消费，所以dead tuples也会被一直保留。

用 pg_drop_replication_slot() 删除废弃不用的复制槽位。

## 僵死或处于孤儿状态的 prepared transaction

在两阶段提交(two-phase commit)中, 需要在第一步创建prepared transaction, 如果因为某种原因prepared transaction一直没有结束，那么从创建这个预事务之后的所有dead tuples无法得到清除。

处理办法，先利用视图 pg_prepared_xacts 列出有哪些僵死的预事务，然后用 rollback prepared transaction_id 来回退该事务。

# PostgreSQL的元组、页面结构及索引查找原理
postgresql数据库通过数据多版本实现mvcc，pg又没有undo段，老版本的数据元组直接存放在数据页面中，这样带来的问题就是旧元组需要不断地进行清理以释放空间，这也是数据库膨胀的根本原因。
## 元组结构
元组，也叫tuple，这个叫法是很学术的叫法，但是现在数据库中一般叫行或者记录。
![](https://ask.qcloudimg.com/http-save/yehe-6832082/kmriv8q269.png)

t_xmin：代表插入此元组的事务xid；

t_xmax：代表更新或者删除此元组的事务xid，如果该元组插入后未进行更新或者删除，t_xmax=0；

t_cid：command id，代表在当前事务中，已经执行过多少条sql，例如执行第一条sql时cid=0，执行第二条sql时cid=1；

t_ctid：保存着指向自身或者新元组的元组标识（tid），由两个数字组成，第一个数字代表物理块号，或者叫页面号，第二个数字代表元组号。在元组更新后tid指向新版本的元组，否则指向自己，这样其实就形成了新旧元组之间的“元组链”，这个链在元组查找和定位上起着重要作用。

了解了元组结构，再简单了解下元组更新和删除过程。

## 更新过程
![](https://ask.qcloudimg.com/http-save/yehe-6832082/5qk1t0krtr.png)
上图中左边是一条新插入的元组，可以看到元组是xid=100的事务插入的，没有进行更新，所t_xmax=0，同时t_ctid指向自己，0号页面的第一号元组。右图是发生xid=101的事务更新该组后的状态，更新在pg里相当于插入一条新元组，原来的元组的t_xmax变为了更新这条事务xid=101，同时t_ctid指针指向了新插入的元组（0,2），0号页面第二号元组，第二号元组t_xmin=101（插入该元组的xid），t_ctid=（0,2），没有发生更新，指向自己。

 ## 删除过程
![](https://ask.qcloudimg.com/http-save/yehe-6832082/g11xebehjz.png)  
上图代表该元组被xid=102的事务删除，将t_xmax设置为删除事务的xid，t_ctid指向自己。

## 页面结构
![](https://ask.qcloudimg.com/http-save/yehe-6832082/5whhgc5btf.jpeg)
从上图可以看到，页面包括三种类型的数据

1.header data：数据头是page生成的时候随之产生的，由pageHeaderData定义结构，24个字节长，包含了page的相关信息，下面是数据结构
```cpp
typedef struct PageHeaderData
{
    /* XXX LSN is member of *any* block, not only page-organized ones */
    PageXLogRecPtr pd_lsn;      /* LSN: next byte after last byte of xlog
                                 * record for last change to this page */
    uint16      pd_checksum;    /* checksum */
    uint16      pd_flags;       /* flag bits, see below */
    LocationIndex pd_lower;     /* offset to start of free space */
    LocationIndex pd_upper;     /* offset to end of free space */
    LocationIndex pd_special;   /* offset to start of special space */
    uint16      pd_pagesize_version;
    TransactionId pd_prune_xid; /* oldest prunable XID, or zero if none */
    ItemIdData  pd_linp[FLEXIBLE_ARRAY_MEMBER]; /* line pointer array */
} PageHeaderData;
```
- pd_lsn: 存储最近改变该页面的xlog位置。
- pd_checksum：存储页面校验和。
- pd_lower，pd_upper：pd_lower指向行指针（line pointer）的尾部，pd_upper指向最后那个元组。
- pd_special: 索引页面中使用，它指向特殊空间的开头。
- 2.line pointer：行指针，四字节，每一条元组会有一个行指针指向真实元组位置。
- 3.heap tuple：存放真实的元组数据，注意元组是从页面的尾部向前堆积的，元组和行指针之间的是数据页的空闲空间。

## 索引查找
看了页面和元组结构，再看看索引的结构。

![](https://ask.qcloudimg.com/http-save/yehe-6832082/n311tp8qnh.png)

以上图为例，索引的数据包含两部分（key=xxx，TID=(block=xxx,offset=xxx)），key表示真实数据，tid代表指向数据行的指针，具体block代表页面号，offset代表行偏移量，指向数据页面的line pointer，比如执行下面的查询语句
```sql
select * from tbl where id=1000;
```
key=1000，根据key值在索引中找到tid为5号页面的1号元组，再通过一号元组行指针找到元组1，检查元组1的t_ctid字段，发现指向了新的元组2，于是定位到真实元组数据2。

# PostgreSQL逻辑复制--常见坑点
## 坑点1: 磁盘空间耗尽

刚使用逻辑复制时，常见到的错误和异常，一般来说导致该异常的原因是subscriber异常退出，但建立的logical slot一直还在，没有删除，导致**$PGDATA/pg_wal**目录占用的磁盘空间不断增长。

方法一

要临时性解决，那就删除对应的slot, 以debezium为例
```sql
select pg_drop_replication_slot('debezium');
```
方法二

设置slot wal允许占用的最大磁盘空间
```sql
max_wal_slot_keep_size = 133143986176 #124GB
```
在启动逻辑复制之后，需要对slot的状态以及pg_wal占用的磁盘空间进行监控，设置好相应的告警以及时排障。

## 坑点2: CPU Usage太高
调高logical_decoding_work_mem值，减少解码后的内容写入到磁盘的次数，默认值是64MB， 可以设置成远高于work_mem的值，注意每个slot会使用一个独立的buffer。

```sql
logical_decoding_work_memo=1024MB
```
如果要同步的内容很多，尽量用多个slot来进行逻辑同步，每个slot同步一部分表的变更。 max_wal_sender控制可以并发同步的数量。

调整同步的变更类型，默认会同步insert, update, delete, 下述sql语句只同步insert带来的变更，忽略update和delete.
```sql
alter publication pg_pub_demo set(publish='insert');
```
## 坑点3: 同步延迟较大

减少checkpoint_timeout和max_wal_size的配置值， 提高checkpoint触发的次数。

同时设置wal_writer_delay和wal_writer_flush_after， 调整为一个合理值。

# 如何杀掉pg数据库正在运行的sql
①使用pg_cancel_backend(pid)杀掉某条sql，这个是温柔的杀，向后台发送sigint信号，关闭当前后台进程，用户只能关闭自己的后台进程，事务回滚。

②使用pg_terminate_backend(pid)杀掉某条sql，这个是强杀，向后台发送sigterm信号，关闭当前后台进程，需要有超级用户权限，超级用户可以关闭所有后台进程，事务回滚。

③这里为什么会有第三种杀法呢？可能大家遇到过，使用pg_cancel_backend杀不掉的进程，但是其实pg_terminate_backend有时也无法杀掉某条sql，笔者在生产环境遇到过，这时我们可能会抓一下该连接的堆栈，然后我们可能想尽快杀掉该sql，问题原因后面再分析，这时我们就要从操作系统层面使用kill命令来杀掉连接了。通过上面查到的pid，在操作系统上ps -ef |grep pid查看当前连接的状态，然后kill -9 pid杀掉该连接。
```sql
postgres=# select pid,query_start,state,query from pg_stat_activity where state='active';
  pid  |          query_start          | state  |                                     query                                      
-------+-------------------------------+--------+--------------------------------------------------------------------------------
  5001 | 2019-08-13 12:45:16.652909+08 | active | select * from perf_analyse;
 18876 | 2019-08-13 12:45:19.019691+08 | active | select pid,query_start,state,query from pg_stat_activity where state='active';
(2 rows)

postgres=# \q
postgres@xxx:~> ps -ef |grep 5001
postgres  5001 23550 64 12:45 ?        00:00:13 postgres: postgres postgres [local] SELECT
postgres  7677  6228  0 12:45 pts/3    00:00:00 grep --color=auto 5001
postgres@xxx:~> kill -9 5001
```
# 查看当前库有哪些 schema
```sql
test-# SELECT schema_name FROM information_schema.schemata;
    schema_name     
--------------------
 pg_toast
 pg_catalog
 public
 information_schema
(4 rows)

test=# \dn
  List of schemas
  Name  |  Owner   
--------+----------
 public | postgres
(1 row)
```

# freeze 机制
在 PostgreSQL 中，**freeze** 机制是为了防止事务 ID (Transaction ID, XID) 的回绕问题。每个事务在 PostgreSQL 中都有一个唯一的事务 ID，当这个 ID 达到最大值时，会重新从 0 开始，这就可能导致数据的混乱。为了避免这种情况，PostgreSQL 引入了 freeze 机制。

### Freeze 机制的工作原理
1. **事务 ID 冻结**：当表中的行变得足够老时，PostgreSQL 会将这些行的事务 ID 替换为一个特殊的冻结 ID。这意味着这些行不再依赖于原始的事务 ID，从而避免了回绕问题³。
2. **自动冻结**：当表的年龄超过 `autovacuum_freeze_max_age`（默认值为 2 亿）时，`autovacuum` 进程会自动对表进行冻结⁵。
3. **VACUUM 命令**：在执行 `VACUUM` 操作时，PostgreSQL 会检查并冻结需要冻结的行。这不仅有助于回收磁盘空间，还能更新统计信息和可见性图²。

### 为什么需要冻结
冻结是为了确保数据库的稳定性和数据一致性。随着时间的推移，事务 ID 会不断增加，如果不进行冻结，最终会导致事务 ID 回绕，进而引发数据错误和系统崩溃³。

### 资源消耗
冻结过程会消耗大量的系统资源，特别是在处理大表时。因此，合理配置 `autovacuum` 参数和定期执行 `VACUUM` 操作是非常重要的，以确保数据库的性能和稳定性⁴。

# 事务号回卷问题
postgresql数据库使用32位事务号，最大容纳42亿左右的事务号，事务号是循环使用的，当事务号耗尽后又会从3开始循环使用。事务环被分为两个半圆，当前事务号过去的21亿事务属于过去的事务号，当前事务号往前的21亿属于未来的事务号，未来的事务号对当前事务是不可见的。

![](https://ask.qcloudimg.com/http-save/yehe-6832082/97ugbaweqr.jpeg)
如上图所示，当前事务号走到了+100，由txid=100的事务号创建的元组（元组的xmin=100）对于当前事务属于过去来说是可见的，当下一个事务+101开启时，该元组就变为未来的事务号了，该元组就变为了不可见。为了解决这个问题，pg引入了冻结事务id的概念，并使用freeze过程实现旧事务号的冻结。

Postgresql有三个特殊事务号：
- 0代表无效事务号；
- 1表示数据库集群初始化的事务id，也就是在执行initdb操作时的事务号；
- 2代表冻结事务id。Txid=2的事务在参与事务id比较时总是比所有事务都旧，冻结的txid始终处理非活跃状态，并且始终对其他事务可见。

如果发生当新老事务id差超过21亿的时候，事务号会发生回卷，此时数据库会报出如下错误并且拒绝接受所有连接，必须进入单用户模式执行vacuum freeze操作。

所以冻结过程应该在平时不断地自动做而不是等到事务号需要回卷的时候才去做。这时就需要引入一个参数：vacuum_freeze_min_age（默认5000万），当冻结过程在扫描表页面元组的时候发现元组xmin比当前事务号current_txid-vacuum_freeze_min_age更小时，就可以将该元组事务id置为2，换个角度理解，也就是对于当前事务来说，如果存在某个元组的事务年龄超过vacuum_freeze_min_age参数值时，就可以在vacuum时把该元组事务号冻结。冻结会将元组结构体中的t_infomask字段置为XMIN_FROZEN。

## 可见性映射VM

可见性映射VM和vacuum有关，vacuum是一个比较消耗资源的操作，为了提高vacuum的效率，让vacuum只扫描存在死元组的页面，而跳过全部都是活跃元组的页面，设计了VM数据结构。在数据base目录，每个表都存在一个对应的vm文件，vm由若干个8k页面组成，类似一个数组结构，记录了该表各个页面上是否包含死亡元组信息。VM结构如下：

![](https://ask.qcloudimg.com/http-save/yehe-6832082/jx4yoovbyh.png)

在9.6以后的版本中，针对冻结过程，vm的功能进行了增强，vm中除了记录死亡元组信息，还记录了页面元组的冻结标识信息。如果页面所有元组都已经被冻结，则置vm中的冻结标识为1，freeze操作就会跳过该页面，提升效率。

## 冻结过程FREEZE
冻结有两种模式，懒惰模式（lazy mode）和急切模式（eager mode）。他们之间的区别在于懒惰模式是跟随者普通vacuum进程进行的，只会扫描包含死元组的页面，而急切模式会扫描所有页面（当然9.6之后已经优化），同时更新相关系统视图frozenxid信息，并且清理无用的clog文件。

在冻结开始时，postgresql会计算freezelimit_txid的值，并冻结xmin小于freezelimit_txid的元组，freezelimit_txid的计算前面也提到过，freezelimit_txid=oldestxmin-vacuum_freeze_min_age，vacuum_freeze_min_age可以理解为一个元组可以做freeze的最小间隔年龄，因为事务回卷的问题，这个值最大设置为20亿，oldestxmin代表当前活跃的所有事务中的最小的事务标识，如果不存在其他事务，那oldestxmin就是当前执行vacuum的事务id。普通vacuum进程会挨个扫描页面，同时配合vm可见性映射跳过不存在死元组的页面，将xmin小于freezelimit_txid的元组t_infomask置为XMIN_FROZEN，清理完成之后，相关统计视图中n_live_tuple、n_dead_tuple、vacuum_count、autovacuum_count、last_autovacuum、last_vacuum之类的统计信息会被更新。

普通的vacuum只会扫描脏页，而freeze操作会扫描所有可见且没有被全部冻结的页面，所以在每次vacuum时都去扫描是不合适的。这时就有了急切冻结模式，急切冻结引入一个参数vacuum_freeze_table_age，同理该参数的最大值也只能是20亿，当表的年龄大于vacuum_freeze_table_age时，会执行急切冻结，表的年龄通过oldestxmin-pg_class.relfrozenxid计算得到，pg_class.relfrozenxid字段是在某个表被冻结后更新的，代表着某个表最近的冻结事务id。而pg_database.relfrozenxid代表着当前库所有表的最小冻结标识，所以只有当该库具有最小冻结标识的表被冻结时，pg_database.relfrozenxid字段才会被更新。急切冻结的触发条件是pg_database.relfrozenxid < oldestxmin-vacuum_freeze_table_age，这其实和上面的说法不冲突，因为某个数据库所有表中的最老的relfrozenxid就是数据库的relfrozenxid，所以冻结可以用一句话来理解：当数据库中存在某个表的年龄大于vacuum_freeze_table_age参数设定值，就会执行急切冻结过程，当表中元组年龄超过vacuum_freeze_min_age，就可以被冻结，这里其实是必须和可以的区别。

## 最佳实践

Freeze是运维好pg数据库必须要十分关注的点。关于freeze有如下三个参数：vacuum_freeze_min_age、vacuum_freeze_table_age、autovacuum_freeze_max_age。前两个参数其实前面介绍的差不多了，感觉这两个参数已经足够了，那么为什么需要第三个参数呢？

下面我们这样假设：vacuum_freeze_min_age=2亿，vacuum_freeze_table_age=19亿，那么只有当表中元组年龄达到2亿时才可以执行freeze操作，这其中部分元组id被置为冻结，部分没有被冻结，同时更新表的relfrozenxid为2亿，然后假设我们从2亿开始表的年龄又过了19亿，这时候表的年龄达到了，这时候会强制执行急切冻结，但是此时新老事务号差距已经达到了21亿，超过了20亿的限制，从另一个角度理解，vacuum_freeze_min_age是相当于在年龄线上增加了一段长度，而且必须有这段长度才能执行freeze操作，这样就不能保证vacuum_freeze_table_age+vacuum_freeze_min_age<20亿，此时就需要单独弄一个参数来保证新老事务差不超过20亿，这个参数就是autovacuum_freeze_max_age。这个参数会强制限制元组的年龄（oldestxmin-xmin）如果超过该值就必须进行急切冻结操作，这个限制是个硬限制。

针对生产环境中，有如下建议：

①autovacuum_freeze_max_age的值应该大于vacuum_freeze_table_age的值，因为如果反过来设置，那么每次当表年龄vacuum_freeze_table_age达到时，autovacuum_freeze_max_age也达到了，那么刚刚做的freeze操作又会去扫描一遍，造成浪费。但是vacuum_freeze_table_age的值也不能太小，太小的话会造成频繁的急切冻结。

②执行急切冻结时，vacuum_freeze_table_age真正的值会去取vacuum_freeze_table_age和0.95*autovacuum_freeze_max_age中的较小值，所以官方建议将vacuum_freeze_table_age设置为0.95*autovacuum_freeze_max_age。

③autovacuum_freeze_max_age和vacuum_freeze_table_age的值也不适合设置过大，因为过大会造成pg_clog中的日志文件堆积，来不及清理。

④vacuum_freeze_min_age不易设置过小，比如我们freeze某个元组后，这个元组马上又被更新，那么之前的freeze操作其实是无用功，freeze真正应该针对的是那些长时间不被更新的元组。

⑤生产环境中做好pg_database.frozenxid的监控，当快达到触发值时，我们应该选择一个业务低峰期窗口主动执行vacuum freeze操作，而不是等待数据库被动触发。

# Oracle、MySQL、PG是如何处理数据库“半页写”的问题的
- mysql为了解决这个问题，引入了“双写”double write，也就是说在将数据页写入磁盘之前先写入一个共享的空间，然后再写入数据文件中。

- oracle对于断页比较“看得开”，他不会从数据库层面去避免发生断页问题，数据库内部没有机制保证断页的处理，它通过其他方面比如rman恢复、adg等方式保证出了问题进行恢复。

- pg通过开启full_page_writes参数（默认开启）来避免断页问题。具体原理是当checkpoint发生后，某个块第一次被更改时将整个页面写入xlog文件中，如果发生块折断，从checkpoint开始从xlog中找到这个数据块的初始完整副本，然后应用redo日志进行恢复。这种方式对性能也有一定影响，但是相比mysql的方式我觉得要好一些，mysql相当于任何一个脏页刷盘前都需要写两份，pg只是在数据块第一次发生变更的时候写入xlog中。  
full_page_writes还有一个作用是用于在线备份，因为basebackup是物理备份，那么有可能发生数据写一半的时候数据块被拷走的情况，这样备份是不可用、不可恢复的。而full_page_writes避免了这一点。  
当然开启full_page_writes的副作用就是增加了xlog的日志量，因为要记录完整页面，另外对性能也有影响，有人测试过大概会有20%-30%的性能影响。